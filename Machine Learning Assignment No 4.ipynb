{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9avhc7QpRNZ",
    "outputId": "3e941356-372b-4ca2-c61d-7ab2b2a6a5ca"
   },
   "source": [
    "# 1. What are the key tasks involved in getting ready to work with machine learning modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "KCm7ge_RpWKI",
    "outputId": "58127828-46be-4390-f4b1-982131b35b98"
   },
   "source": [
    "Ans: The Key Tasks involved in Machine learning Modelling are:\n",
    "1.\tPreparing HLD, SLD, Architecture, Wireframe, KPI, pipeline, production documents or processes.\n",
    "2.\tData Sharing Agreement: defining the data after understanding the problem statement \n",
    "3.\tData validation: validating the file name, file extension, column name, no of column, type of features, feature name, and checking missing value. \n",
    "4.\tData collection: Defining the problem and assembling a dataset.\n",
    "5.\tData preparation: Preparing your data.\n",
    "6.\tChoosing a Model\n",
    "7.\tTraining the Model: Developing a model that does better than a baseline.\n",
    "8.\tEvaluating the Model: Choosing a measure of success. Deciding on an evaluation protocol.\n",
    "9.\tParameter tuning: Scaling up: developing a model that overfits. Regularizing your model and tuning your parameters.\n",
    "10.\tPrediction or Inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "U3yxFOEqpWs3",
    "outputId": "87a52025-ba3f-44b6-e906-38b4ebf28d2b"
   },
   "source": [
    "# 2. What are the different forms of data used in machine learning? Give a specific example for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "t2KdVpW9pYd3",
    "outputId": "f330d21c-1fac-4586-b309-df52ea34f2bf"
   },
   "source": [
    "Ans:- Mostly data is categorized into 4 types from a Machine Learning perspective: numerical data, categorical data, time-series data, and text data.\n",
    "1. Numerical Data: Numerical data represent values that can be measured and in logical order. Examples of numerical data are height, weight, age, number of movies watched, IQ, etc. To graph numerical data, one uses dot plots, stem and leaf graphs, histograms, box plots, ogive graphs, and scatter plots.\n",
    "2. Categorical Data: Categorical data is a type of data that can be stored into groups or categories and can named or labelled or classes. Matching technique is used to make groups based on the similarity of the data. \n",
    "3. Time-Series Data: Time series data is data that is collected at different points in time. For ex Sales forecasting, seasonal sales etc. Because data points in time series are collected at adjacent time period we can use correlation between observations to draw from conclusion or observations. \n",
    "4. Text Data: Text data usually consists of documents which can represent words, sentences or even paragraphs of free flow or unstructured text. Unstructured (no neatly formatted data columns!) and noisy nature of textual data makes it harder for machine learning methods to draw conclusion or predictions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "vvRXg5RvpYoB",
    "outputId": "492a0c07-99d1-48e3-dc25-621e952b1a9f"
   },
   "source": [
    "# 3. Distinguish:\n",
    "1.\tNumeric vs. categorical attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "BOuc43i7pY0N",
    "outputId": "52af6643-bd09-4717-dd8f-f7fc0f9e390a"
   },
   "source": [
    "•\tNumerical data is used for quantitative analysis, and have magnitude (hence, they are always numbers or symbols carrying a numerical value). Categorical data is used for qualitative analysis, categorical data do not have magnitude.\n",
    "•\tNumerical data belongs to ordinal, ratio, or interval type, whereas categorical data belong to nominal type.\n",
    "•\tMethods used to analyse quantitative data are different from the methods used for categorical data, principles are same however the application varies significantly.\n",
    "•\tNumerical data is used for analysed using statistical methods such as descriptive statistics, regression, time series and many more.\n",
    "•\tCategorical data is used for descriptive methods and graphical methods. And also some non-parametric tests.\n",
    "1.\tFeature selection vs. dimensionality reduction\n",
    "2.\tThe main difference between Feature selection and dimensionality reduction is that the set of features selected from feature selection must be a subset of the original set of features, whereas set made by dimensionality reduction doesn't have to be a subset but it is a combination of features (for instance PCA reduces dimensionality by making new synthetic features from linear combination of the original ones, and then discarding the less important ones).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "s0topvR7p-Jf",
    "outputId": "d44e12b7-97a0-44c9-8d41-981555a6fa4d"
   },
   "source": [
    "# 5. Why is it necessary to investigate data? Is there a discrepancy in how qualitative and quantitative data are explored?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "VQbnoTtyp_YO",
    "outputId": "4e207a04-500f-4650-8d94-04c253f39212"
   },
   "source": [
    "Sol. If your data set is messy or noisy, only model building will not solve your problem. What will happen is “garbage in, garbage out.” In order to build a robust machine learning algorithm. We need to exploratory data analysis and understand our data set before we define a predictive task and making prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "SlKTuJYGpnNm",
    "outputId": "f4b39026-3576-4426-f721-38393303dc4d"
   },
   "source": [
    "# 6. What are the various histogram shapes? What exactly are “bins”?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "mQUpTvrDqPbd",
    "outputId": "b9769472-c534-4754-9bed-53abd42e8c9f"
   },
   "source": [
    "When a data set contains so many different values that we cannot conveniently associate them with individual bars in a histogram, we use binning. That is, we define a range of values as a bin, group measurements into these bins, and create one bar for each bin.\n",
    "i. The histogram\n",
    "Bell-shaped: A bell-shaped picture, shown below, usually presents a normal distribution. \n",
    "ii. A bimodal shape, shown below, has two peaks. This shape may show that the data has come from two different systems. If this shape occurs, the two sources should be separated and analyzed separately.\n",
    "iii. Skewed right: Some histograms will show a skewed distribution to the right, as shown below. A distribution skewed to the right is said to be positively skewed. This kind of distribution has a large number of occurrences in the lower value cells (left side) and few in the upper value cells (right side). A skewed distribution can result when data is gathered from a system with has a boundary such as zero. In other words, all the collected data has values greater than zero. \n",
    "iv. Skewed left: Some histograms will show a skewed distribution to the left, as shown below. A distribution skewed to the left is said to be negatively skewed. This kind of distribution has a large number of occurrences in the upper value cells (right side) and few in the lower value cells (left side). A skewed distribution can result when data is gathered from a system with a boundary such as 100. In other words, all the collected data has values less than 100.\n",
    "V. Uniform: A uniform distribution, as shown below, provides little information about the system. An example would be a state lottery, in which each class has about the same number of elements. It may describe a distribution which has several modes (peaks). If your histogram has this shape, check to see if several sources of variation have been combined. If so, analyze them separately. If multiple sources of variation do not seem to be the cause of this pattern, different groupings can be tried to see if a more useful pattern results. This could be as simple as changing the starting and ending points of the cells, or changing the number of cells. A uniform distribution often means that the number of classes is too small.\n",
    "vi. Random: A random distribution, as shown below, has no apparent pattern. Like the uniform distribution, it may describe a distribution that has several modes (peaks). If your histogram has this shape, check to see if several sources of variation have been combined. If so, analyze them separately. If multiple sources of variation do not seem to be the cause of this pattern, different groupings can be tried to see if a more useful pattern results. This could be as simple as changing the starting and ending points of the cells, or changing the number of cells. A random distribution often means there are too many classes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "jSh_rIlupnZJ",
    "outputId": "945bfc86-d2ab-44f4-dbee-81b0e3b3f03d"
   },
   "source": [
    "# 7. How do we deal with data outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Deleting the values: We can delete the outliers if we know outliers are wrong or if the reason of the outlier is never going to happen in the future. For example, there is a data set of peoples ages and the usual ages lie between 0 to 90 however when data entered is of the age 150 years old person which is impossible. So, we can safely drop the value of “150 years person”.\n",
    "2. Changing the values: We can also change the values in case when we know the reason for the outliers. For example: for measurement or instrument errors where we had 10 voltmeters out of which one voltmeter was faulty. So, we can take another set of readings using a correct voltmeter and replace them with the readings that were taken by the faulty voltmeter.\n",
    "3. Data transformation: Data transformation is useful when we are dealing with highly skewed/ imbalanced data sets. By transforming the variables, we can eliminate the outliers for example by taking the natural log of a value will reduce the variation caused by the extreme values. This can also be done for data sets that do not have negative values. Data transformation can also be done using square and cube transformation. \n",
    "4. Using different analysis methods: We can also use statistical tests which are not much impacted by the presence of outliers – for example we can use median to compare data sets instead of mean or use of equivalent nonparametric tests etc.\n",
    "5. Valuing the outliers: In case there is a valid reason for the outlier to exist and it is a part of our natural process, we should investigate the cause of the outlier as it can provide valuable clues that can help us in understand your process performance. Outliers may have some unique information that could be invaluable to improve your process performance. We need to understand the special causes that contributed to the outliers. Fixing these special causes can give you significant boost in your process performance. For example, normal delivery of orders takes 1-2 days, but a few orders took more than a month to complete. Understanding the reason why it took a month and fixing this problem can help future customers as they would not be impacted by such long waiting time.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "H_vtoNh6pnjf",
    "outputId": "7ced1ef2-b163-4d59-cc4f-b1995bbe7f1b"
   },
   "source": [
    "# 8. What are the various central inclination measures? Why does mean vary too much from median in certain data sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "lbsNvhN2pnsu",
    "outputId": "986fb6bf-eb21-4bb6-d667-d95451eb9dff"
   },
   "source": [
    "Sol. It is also known as measure of central tendency. This measures an important way to summarize the dataset with one representative value. It provides a rough picture of where data points are centred. The commonly used terms for measuring central tendency are:\n",
    "•\tMean\n",
    "•\tMedian\n",
    "•\tMode\n",
    "The median is generally used for skewed distributions or imbalanced data. The mean is not a robust tool since it is largely influenced by outliers. A mean is computed by adding up all the values and dividing that score by the total number of values. The Median is the exact middle of the set of values when data points are odd and when the data points are even then it is the mean of the middle values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "bdA8LnLYpnzC",
    "outputId": "1b5caa8d-7003-4c4d-df4e-75e406d25891"
   },
   "source": [
    "# 9. Describe how a scatter plot can be used to investigate bivariate relationships. Is it possible to find outliers using a scatter plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "GososgdHpXGa",
    "outputId": "79bff85f-b331-4dfd-f396-c34e934f5c2e"
   },
   "source": [
    "Bivariate analysis: it is used to find the relationship in the dataset for each variable and the target variable of interest (or) using 2 variables and then finding the relationship between them. Scatter plots illustrates how much one variable is affected by another. The relationship between two variables is called correlation. If the line goes from a high-value on the y-axis down to a high-value on the x-axis, the variables have a negative correlation. A perfect positive correlation is given the value of 1.\n",
    "If there is a regression line on a scatter plot, you can easily identify outliers. An outlier on a scatter plot is the point or points that are farthest from the regression line. If one point on a scatter plot is farther from the regression line than some other point, then the scatter plot has at least one outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "iI8dCiTlqFHr",
    "outputId": "fda420a9-0ab0-4284-a9b6-efcaed19f8c9"
   },
   "source": [
    "# 10. Describe how cross-tabs can be used to figure out how two variables are related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "FRbZG2eSqHaX",
    "outputId": "77702414-5914-49a7-e4a6-90f774169890"
   },
   "source": [
    "'Cross tabulation is a method to quantitatively analyse the relationship between multiple variables. It is also known as contingency tables or cross tabs, cross tabulation groups variables to understand the correlation between different variables. It also shows how correlations change from one variable groups to another.'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
